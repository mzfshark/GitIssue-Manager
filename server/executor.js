#!/usr/bin/env node
/* eslint-env node */
/* global require, console, process */
// Server-side executor (engine):
// - Reads engine-input.json generated by client/prepare.js
// - Creates/updates issues in mzfshark/* repos (idempotent via stableId)
// - Optionally attaches issues to ProjectV2 and updates estimate field

const fs = require('fs');
const path = require('path');
const crypto = require('crypto');
const { execFileSync } = require('child_process');

const GH_MIN_DELAY_MS = Number.parseInt(process.env.GITISSUER_GH_MIN_DELAY_MS || '250', 10);
const USE_SEARCH_FALLBACK = process.env.GITISSUER_USE_SEARCH_FALLBACK === '1';
let lastGhCallAtMs = 0;

function sha1(str) {
	return crypto.createHash('sha1').update(str).digest('hex');
}

function readJson(p) { return JSON.parse(fs.readFileSync(p, 'utf8')); } // nosemgrep
function writeJson(p, obj) { fs.mkdirSync(path.dirname(p), { recursive: true }); fs.writeFileSync(p, JSON.stringify(obj, null, 2)); } // nosemgrep

function isRateLimitError(err) {
	const msg = String((err && err.message) || '');
	const stderr = String((err && err.stderr) || '');
	const combined = `${msg}\n${stderr}`.toLowerCase();
	return (
		combined.includes('api rate limit exceeded') ||
		combined.includes('secondary rate limit') ||
		combined.includes('abuse detection') ||
		(combined.includes('http 403') && combined.includes('rate limit'))
	);
}

function toRateLimitError(err) {
	const msg = String((err && err.message) || 'rate-limited');
	const oneLine = msg.replace(/\s+/g, ' ').trim().slice(0, 240);
	const e = new Error(`RATE_LIMIT: ${oneLine}`);
	e.cause = err;
	return e;
}

function throttleGh() {
	if (!Number.isFinite(GH_MIN_DELAY_MS) || GH_MIN_DELAY_MS <= 0) return;
	const now = Date.now();
	const elapsed = now - lastGhCallAtMs;
	if (elapsed < GH_MIN_DELAY_MS) {
		sleepMs(GH_MIN_DELAY_MS - elapsed);
	}
	lastGhCallAtMs = Date.now();
}

function ghApiWithRetry(args, opts = {}) {
	const maxAttempts = typeof opts.maxAttempts === 'number' ? opts.maxAttempts : 6;
	for (let attempt = 1; attempt <= maxAttempts; attempt++) {
		try {
			throttleGh();
			const out = execFileSync('gh', ['api', ...args], { encoding: 'utf8' });
			return JSON.parse(out);
		} catch (e) {
			if (e && e.stdout) {
				try { return JSON.parse(e.stdout.toString()); } catch (_) {}
			}
			if (isRateLimitError(e) && attempt < maxAttempts) {
				const backoffMs = Math.min(60000, 1500 * (2 ** (attempt - 1)));
				console.warn(`[WARN] gh api rate-limited (attempt ${attempt}/${maxAttempts}); backing off ${backoffMs}ms...`);
				sleepMs(backoffMs);
				continue;
			}
			if (isRateLimitError(e)) {
				throw toRateLimitError(e);
			}
			throw e;
		}
	}
	throw new Error('Unreachable');
}

function ghExecWithRetry(args, opts = {}) {
	const maxAttempts = typeof opts.maxAttempts === 'number' ? opts.maxAttempts : 6;
	for (let attempt = 1; attempt <= maxAttempts; attempt++) {
		try {
			throttleGh();
			return execFileSync('gh', ['api', ...args], { encoding: 'utf8' });
		} catch (e) {
			if (isRateLimitError(e) && attempt < maxAttempts) {
				const backoffMs = Math.min(60000, 1500 * (2 ** (attempt - 1)));
				console.warn(`[WARN] gh api rate-limited (attempt ${attempt}/${maxAttempts}); backing off ${backoffMs}ms...`);
				sleepMs(backoffMs);
				continue;
			}
			if (isRateLimitError(e)) {
				throw toRateLimitError(e);
			}
			throw e;
		}
	}
	throw new Error('Unreachable');
}

function ghApi(args) {
	return ghApiWithRetry(args);
}

function ghExec(args) {
	return ghExecWithRetry(args);
}

function sleepMs(ms) {
	if (!ms || ms <= 0) return;
	// Avoid async refactor; Block the event loop briefly for rate-limit backoff.
	// This is acceptable for a CLI tool.
	Atomics.wait(new Int32Array(new SharedArrayBuffer(4)), 0, 0, ms);
}

function repoIsAllowed(repo) {
	// Allow mzfshark/* and Axodus/* repos
	return repo && (repo.startsWith('mzfshark/') || repo.startsWith('Axodus/'));
}

function normalizeLabels(labels, extra = []) {
	const combined = [...(Array.isArray(labels) ? labels : []), ...extra];
	return Array.from(new Set(combined.map((l) => String(l).trim()).filter(Boolean)));
}

// --- Title helpers (repo prefix + #TYPE-NNN pattern) ---
function getRepoName(fullRepo) {
	if (!fullRepo) return '';
	const parts = String(fullRepo).split('/');
	return parts.length === 2 ? parts[1] : String(fullRepo);
}

function findExplicitId(originalText) {
	if (!originalText) return null;
	const t = String(originalText).trim();
	// Matches TYPE-NNN or TYPE_NNN at the start (2+ digits on the number)
	const m = t.match(/^([A-Za-z]+)[-_](\d{2,})\b/);
	if (!m) return null;
	const type = m[1].toUpperCase();
	const num = m[2];
	return `${type}-${num}`;
}

function stripLeadingId(originalText) {
	if (!originalText) return '';
	// Remove the leading TYPE-NNN / TYPE_NNN and trailing separators like ":", "-", or spaces
	return String(originalText).trim().replace(/^([A-Za-z]+)[-_](\d{2,})\b[:\-\s]*/, '').trim();
}

function stripInlineShortcodes(originalText) {
	if (!originalText) return '';
	// Remove inline metadata shortcodes like: [priority:high] [estimate:2h] [labels:foo,bar]
	// Keep bracketed human prefixes like "[Backend]" intact by only stripping tags that contain ":".
	return String(originalText)
		.replace(/\[[A-Za-z][A-Za-z0-9_-]*:[^\]]+\]/g, '')
		.replace(/\s{2,}/g, ' ')
		.trim();
}

function findTypeFromItem(item) {
	const explicitId = item && item.explicitId ? String(item.explicitId) : findExplicitId(item && item.text);
	if (explicitId) return explicitId.split('-')[0].toUpperCase();
	const labels = Array.isArray(item && item.labels) ? item.labels : [];
	for (const l of labels) {
		const m = String(l).match(/^type:(.+)$/i);
		if (!m) continue;
		const t = String(m[1]).trim().toUpperCase();
		if (t === 'BUG' || t === 'FEATURE' || t === 'HOTFIX' || t === 'TASK') return t;
	}
	return 'TASK';
}

function getBreadcrumbSegments(item, byStableId) {
	const segments = [];
	const visited = new Set();
	let cur = item;
	let depth = 0;
	while (cur && depth < 20) {
		const sid = cur.stableId;
		if (!sid || visited.has(sid)) break;
		visited.add(sid);
		segments.push(cur);
		cur = (cur.parentStableId && byStableId && byStableId[cur.parentStableId]) ? byStableId[cur.parentStableId] : null;
		depth += 1;
	}
	segments.reverse();
	const context = [];
	for (const s of segments) {
		const t = findTypeFromItem(s);
		if (t === 'PLAN' || t === 'EPIC' || t === 'SPRINT') {
			if (!context.length || context[context.length - 1] !== t) context.push(t);
		}
	}
	const leafType = findTypeFromItem(item);
	if (leafType === 'PLAN' || leafType === 'EPIC' || leafType === 'SPRINT') return [leafType];
	return context.length ? context.concat([leafType]) : [leafType];
}

function buildBreadcrumbTitle(item, byStableId) {
	const segments = getBreadcrumbSegments(item, byStableId);
	const rest = stripInlineShortcodes(stripLeadingId(item && item.text ? item.text : ''));
	const combined = rest ? `[${segments.join(' / ')}] - ${rest}` : `[${segments.join(' / ')}]`;
	return combined.trim();
}

/**
 * Build issue body for parent plan issues.
 * Uses full file content wrapped in collapsible details if large.
 */
function buildParentIssueBody(item) {
	const markers = [
		`<!-- Source: ${item.file}#L${item.line} -->`,
		item.canonicalKey ? `<!-- Key: ${item.canonicalKey} -->` : null,
		`<!-- StableId: ${item.stableId} -->`,
		item.body ? `<!-- ContentHash: ${sha1(item.body)} -->` : null,
	].filter(Boolean).join('\n');

	// Wrap large content in collapsible details for readability
	let contentSection = '';
	if (item.body) {
		if (item.body.length > 1000) {
			contentSection = `\n\n<details>\n<summary>ðŸ“„ Plan Content (click to expand)</summary>\n\n${item.body}\n\n</details>`;
		} else {
			contentSection = `\n\n${item.body}`;
		}
	}

	return `${markers}${contentSection}`;
}

function buildIssueBody(item) {
	// NEW: Use parent body builder for parent plan issues
	if (item.isParentPlan) {
		return buildParentIssueBody(item);
	}

	// Standard body for regular tasks/subtasks
	const lines = [`Source: ${item.file}#L${item.line}`];
	if (item.canonicalKey) lines.push(`Key: ${item.canonicalKey}`);
	lines.push(`StableId: ${item.stableId}`);
	lines.push('');
	lines.push(item.text || '');
	return lines.join('\n');
}

function buildIssueTitle(fullRepo, originalText) {
	const repo = getRepoName(fullRepo);
	const explicitId = findExplicitId(originalText);
	const rest = stripInlineShortcodes(stripLeadingId(originalText));
	const prefix = explicitId ? `[${repo} | #${explicitId}]` : `[${repo}]`;
	const combined = rest ? `${prefix} ${rest}` : `${prefix}`;
	return combined.trim();
}

function extractStableIdFromBody(body) {
	if (!body) return null;
	const m = String(body).match(/\bStableId\s*:\s*([0-9a-f]{16,64})\b/i);
	return m ? m[1] : null;
}

function extractCanonicalKeyFromBody(body) {
	if (!body) return null;
	const m = String(body).match(/\bKey\s*:\s*([^\s]+)\b/i);
	return m ? m[1] : null;
}

function extractSourcePathFromBody(body) {
	if (!body) return null;
	const m = String(body).match(/\bSource:\s*([^\s#]+)(?:#L\d+)?/i);
	if (!m) return null;
	return String(m[1]).trim();
}

// Cache issue lookup indices by repo to reduce Search API calls.
// Shape: { [repo]: { byStableId: Record<string, Issue>, byKey: Record<string, Issue> } }
const stableIdIndexCache = {};

// Optional preflight cache loaded from github-state.json
// Shape: { [repo]: { byStableId: Record<string, any>, byKey: Record<string, any>, byStableMeta: Record<string, {updatedAt?:string, number?:number}> } }
const githubStateIndexCache = {};

function resolveGithubStatePathFromConfig(configPath, config, repo, baseDir) {
	try {
		const configured = config && config.outputs && config.outputs.githubStatePath ? String(config.outputs.githubStatePath) : '';
		const root = baseDir || process.cwd();
		if (configured) return path.isAbsolute(configured) ? configured : path.resolve(root, configured);
		// Default to per-repo tmp folder: ./tmp/<owner>-<repo>/github-state.json
		const ownerName = (config && config.owner) ? String(config.owner) : (repo && repo.includes('/') ? repo.split('/')[0] : 'mzfshark');
		const repoName = repo && repo.includes('/') ? repo.split('/')[1] : (repo || 'repo');
		return path.resolve(root, 'tmp', `${ownerName}-${repoName}`, 'github-state.json');
	} catch (_) {
		return null;
	}
}

function loadGithubStateIndex(repo, githubStatePath) {
	if (!repo || !githubStatePath) return null;
	if (githubStateIndexCache[repo]) return githubStateIndexCache[repo];
	if (!fs.existsSync(githubStatePath)) return null;
	try {
		const data = readJson(githubStatePath);
		if (!data || data.repo !== repo || !Array.isArray(data.issues)) return null;
		const idx = { byStableId: {}, byKey: {}, byStableMeta: {}, bySourceTitle: {} };
		for (const it of data.issues) {
			if (!it || !it.stableId || !it.number) continue;
			// executor expects an object shaped similarly to the gh issues REST response (at least: number, body)
			const issueLike = {
				number: it.number,
				node_id: it.nodeId || null,
				title: it.title || null,
				state: it.state || null,
				updated_at: it.updatedAt || null,
				labels: Array.isArray(it.labels) ? it.labels.map((n) => ({ name: n })) : [],
				assignees: Array.isArray(it.assignees) ? it.assignees.map((login) => ({ login })) : [],
				body: it.body || '',
			};
			idx.byStableId[String(it.stableId)] = issueLike;
			const key = extractCanonicalKeyFromBody(issueLike.body);
			if (key) idx.byKey[key] = issueLike;
			idx.byStableMeta[String(it.stableId)] = { updatedAt: it.updatedAt || null, number: it.number };
			const sourcePath = extractSourcePathFromBody(issueLike.body);
			if (sourcePath && issueLike.title) {
				const sourceKey = `${sourcePath}::${issueLike.title}`;
				idx.bySourceTitle[sourceKey] = issueLike;
			}
		}
		githubStateIndexCache[repo] = idx;
		return idx;
	} catch (e) {
		return null;
	}
}

function loadRegistryLastSyncedAt(repoRootAbs) {
	try {
		const p = path.join(repoRootAbs, '.gitissuer', 'registry', 'issue-registry.json');
		if (!fs.existsSync(p)) return null;
		const reg = readJson(p);
		const items = Array.isArray(reg && reg.items) ? reg.items : [];
		const map = new Map();
		for (const it of items) {
			if (!it || !it.stableId || !it.lastSyncedAt) continue;
			map.set(String(it.stableId), String(it.lastSyncedAt));
		}
		return map;
	} catch (e) {
		return null;
	}
}

function loadStableIdIndex(repo) {
	if (stableIdIndexCache[repo]) return stableIdIndexCache[repo];
	// If preflight fetch produced github-state.json, prefer it to avoid GitHub API churn.
	if (githubStateIndexCache[repo]) {
		stableIdIndexCache[repo] = {
			byStableId: githubStateIndexCache[repo].byStableId || {},
			byKey: githubStateIndexCache[repo].byKey || {},
			bySourceTitle: githubStateIndexCache[repo].bySourceTitle || {},
		};
		return stableIdIndexCache[repo];
	}
	const index = { byStableId: {}, byKey: {}, bySourceTitle: {} };
	let page = 1;
	let hasMore = true;
	while (hasMore) {
		let items;
		try {
			// Avoid Search API (prone to secondary rate limits). List issues by label instead.
			items = ghApi([
				`repos/${repo}/issues`,
				'-X',
				'GET',
				'-f',
				'state=all',
				'-f',
				'labels=sync-md',
				'-f',
				'per_page=100',
				'-f',
				`page=${page}`,
			]);
		} catch (e) {
			// Fail-closed on rate limits; returning an empty index risks duplicate creation.
			if (String(e && e.message || '').includes('RATE_LIMIT') || isRateLimitError(e)) {
				throw (String(e && e.message || '').includes('RATE_LIMIT') ? e : toRateLimitError(e));
			}
			console.warn('[WARN] could not pre-load issues for stableId index:', String(e && e.message || '').substring(0, 120));
			break;
		}
		if (!Array.isArray(items) || items.length === 0) break;
		for (const issue of items) {
			// Skip PRs returned by the issues endpoint.
			if (issue && issue.pull_request) continue;
			const stableId = extractStableIdFromBody(issue.body);
			if (stableId) index.byStableId[stableId] = issue;
			const key = extractCanonicalKeyFromBody(issue.body);
			if (key) index.byKey[key] = issue;
			const sourcePath = extractSourcePathFromBody(issue.body);
			if (sourcePath && issue.title) {
				const sourceKey = `${sourcePath}::${issue.title}`;
				index.bySourceTitle[sourceKey] = issue;
			}
		}
		if (items.length < 100) {
			hasMore = false;
			break;
		}
		page += 1;
		sleepMs(150);
	}
	stableIdIndexCache[repo] = index;
	return index;
}

function findIssueByCanonicalKey(repo, canonicalKey, forceSearch = false) {
	if (!canonicalKey) return null;
	const idx = loadStableIdIndex(repo);
	if (idx && idx.byKey && idx.byKey[canonicalKey]) {
		const hit = idx.byKey[canonicalKey];
		console.log('[DEBUG] Found existing issue (index):', hit.number, 'for key', String(canonicalKey).substring(0, 12));
		return hit;
	}

	if (!USE_SEARCH_FALLBACK && !forceSearch) return null;

	// Last resort (opt-in): Search API. This may hit secondary rate limits; keep it disabled by default.
	// Quote the token to avoid parsing as search syntax.
	const q = `repo:${repo} "Key: ${canonicalKey}"`;
	for (let attempt = 1; attempt <= 2; attempt++) {
		try {
			const res = ghApi(['search/issues', '-X', 'GET', '-f', `q=${q}`]);
			if (res && res.total_count && res.items && res.items.length) {
				console.log('[DEBUG] Found existing issue (search):', res.items[0].number, 'for key', String(canonicalKey).substring(0, 12));
				return res.items[0];
			}
			return null;
		} catch (e) {
			const msg = String(e && e.message || '');
			if (msg.includes('RATE_LIMIT') || isRateLimitError(e)) {
				throw (msg.includes('RATE_LIMIT') ? e : toRateLimitError(e));
			}
			if (!msg.includes('HTTP 404')) {
				console.warn('[WARN] search issues failed:', msg.substring(0, 120));
			}
			return null;
		}
	}
	return null;
}

function findIssueByStableId(repo, stableId, forceSearch = false) {
	const idx = loadStableIdIndex(repo);
	if (idx && idx.byStableId && idx.byStableId[stableId]) {
		const hit = idx.byStableId[stableId];
		console.log('[DEBUG] Found existing issue (index):', hit.number, 'for', stableId.substring(0, 10));
		return hit;
	}

	if (!USE_SEARCH_FALLBACK && !forceSearch) return null;

	// Last resort (opt-in): Search API. This may hit secondary rate limits; keep it disabled by default.
	const q = `repo:${repo} StableId:${stableId}`;
	for (let attempt = 1; attempt <= 2; attempt++) {
		try {
			const res = ghApi(['search/issues', '-X', 'GET', '-f', `q=${q}`]);
			if (res && res.total_count && res.items && res.items.length) {
				console.log('[DEBUG] Found existing issue (search):', res.items[0].number, 'for', stableId.substring(0, 10));
				return res.items[0];
			}
			return null;
		} catch (e) {
			const msg = String(e && e.message || '');
			if (msg.includes('RATE_LIMIT') || isRateLimitError(e)) {
				throw (msg.includes('RATE_LIMIT') ? e : toRateLimitError(e));
			}
			if (!msg.includes('HTTP 404')) {
				console.warn('[WARN] search issues failed:', msg.substring(0, 120));
			}
			return null;
		}
	}
	return null;
}

function findIssueBySourceTitle(repo, sourcePath, title, forceSearch = false) {
	if (!repo || !sourcePath || !title) return null;
	const idx = loadStableIdIndex(repo);
	if (idx && idx.bySourceTitle) {
		const key = `${sourcePath}::${title}`;
		const hit = idx.bySourceTitle[key];
		if (hit) {
			console.log('[DEBUG] Found existing issue (source+title):', hit.number, 'for', sourcePath);
			return hit;
		}
	}
	if (!USE_SEARCH_FALLBACK && !forceSearch) return null;
	const q = `repo:${repo} "Source: ${sourcePath}" "${title}"`;
	for (let attempt = 1; attempt <= 2; attempt++) {
		try {
			const res = ghApi(['search/issues', '-X', 'GET', '-f', `q=${q}`]);
			if (res && res.total_count && res.items && res.items.length) {
				console.log('[DEBUG] Found existing issue (search source+title):', res.items[0].number, 'for', sourcePath);
				return res.items[0];
			}
			return null;
		} catch (e) {
			const msg = String(e && e.message || '');
			if (msg.includes('RATE_LIMIT') || isRateLimitError(e)) {
				throw (msg.includes('RATE_LIMIT') ? e : toRateLimitError(e));
			}
			if (!msg.includes('HTTP 404')) {
				console.warn('[WARN] search issues failed:', msg.substring(0, 120));
			}
			return null;
		}
	}
	return null;
}

function extractInvalidLabelsFromApiError(response) {
	if (!response || typeof response !== 'object') return [];
	const errors = Array.isArray(response.errors) ? response.errors : [];
	const invalid = [];
	for (const e of errors) {
		if (!e || typeof e !== 'object') continue;
		const code = String(e.code || '').toLowerCase();
		const field = String(e.field || '').toLowerCase();
		const value = e.value != null ? String(e.value) : '';
		if ((code === 'invalid' || code === 'missing_field') && field === 'labels' && value) invalid.push(value);
	}
	return invalid;
}

function stripInvalidLabels(labels, invalid) {
	if (!Array.isArray(labels) || labels.length === 0) return [];
	if (!Array.isArray(invalid) || invalid.length === 0) return labels.slice();
	const bad = new Set(invalid.map((x) => String(x).toLowerCase()));
	return labels.filter((l) => !bad.has(String(l).toLowerCase()));
}

function isDoneStatus(status) {
	if (!status) return false;
	const s = String(status).trim().toUpperCase();
	return s === 'DONE' || s === 'COMPLETED' || s === 'CLOSED' || s === 'MERGED';
}

function desiredIssueStateFromItem(item) {
	// Default: keep issues open unless explicitly marked done.
	if (!item) return 'open';
	if (isDoneStatus(item.status)) return 'closed';
	// Some plans might only use checkboxes; treat checked items as done.
	if (item.checked === true) return 'closed';
	return 'open';
}

function setIssueState(repo, number, desiredState) {
	if (!repo || !number || !desiredState) return null;
	const state = String(desiredState).toLowerCase();
	if (state !== 'open' && state !== 'closed') return null;
	return ghApi([`repos/${repo}/issues/${number}`, '-X', 'PATCH', '-f', `state=${state}`]);
}

function createIssue(repo, title, body, labels, assignee) {
	const attemptCreate = (labelList) => {
		const args = [`repos/${repo}/issues`, '-f', `title=${title}`, '-f', `body=${body}`];
		for (const l of labelList || []) args.push('-f', `labels[]=${l}`);
		if (assignee) args.push('-f', `assignees[]=${assignee}`);
		return ghApi(args);
	};

	try {
		let out = attemptCreate(labels || []);
		// If API returned an error object (no number), persist diagnostic info for post-mortem.
		if (out && !out.number && out.message) {
			try {
				const diag = {
					ts: new Date().toISOString(),
					repo: repo,
					title: title ? String(title).slice(0, 200) : '',
					bodyPreview: body ? String(body).slice(0, 1000) : '',
					labels: labels || [],
					assignee: assignee || null,
					response: out
				};
				const diagPath = path.join(process.cwd(), 'tmp', `github-create-error-${Date.now()}.json`);
				writeJson(diagPath, diag);
				console.warn(`[DIAG] Wrote GitHub create-error diagnostic to ${diagPath}`);
			} catch (diagErr) {
				console.warn('[DIAG] Failed to write GitHub diagnostic file:', String(diagErr && diagErr.message));
			}
		}
		if (out && !out.number && out.message) {
			const invalid = extractInvalidLabelsFromApiError(out);
			if (invalid.length > 0) {
				const filtered = stripInvalidLabels(labels || [], invalid);
				console.warn(`WARN: createIssue failed due to invalid label(s): ${invalid.join(', ')}; retrying without them.`);
				out = attemptCreate(filtered);
			}
		}
		if (out && !out.number && out.message) {
			const suffix = out.errors ? ` errors=${JSON.stringify(out.errors).slice(0, 300)}` : '';
			throw new Error(`GitHub API error creating issue: ${out.message}${suffix}`);
		}
		return out;
	} catch (e) {
		if (e && e.message && String(e.message).includes('rate limit')) {
			throw new Error('RATE_LIMIT: ' + String(e.message).substring(0, 160));
		}
		throw e;
	}
}

function updateIssue(repo, number, title, body, labels) {
	const attemptUpdate = (labelList) => {
		const args = [`repos/${repo}/issues/${number}`, '-X', 'PATCH', '-f', `title=${title}`, '-f', `body=${body}`];
		for (const l of labelList || []) args.push('-f', `labels[]=${l}`);
		return ghApi(args);
	};

	let out = attemptUpdate(labels || []);
	if (out && !out.number && out.message) {
		const invalid = extractInvalidLabelsFromApiError(out);
		if (invalid.length > 0) {
			const filtered = stripInvalidLabels(labels || [], invalid);
			console.warn(`WARN: updateIssue #${number} failed due to invalid label(s): ${invalid.join(', ')}; retrying without them.`);
			out = attemptUpdate(filtered);
		}
	}
	if (out && !out.number && out.message) {
		const suffix = out.errors ? ` errors=${JSON.stringify(out.errors).slice(0, 300)}` : '';
		throw new Error(`GitHub API error updating issue #${number}: ${out.message}${suffix}`);
	}
	return out;
}

function graphql(query, variables) {
	// NOTE: `gh api graphql` does not reliably support passing variables as `variables=@file`.
	// Instead, pass variables individually using `-F name=value`.
	// This helper only supports flat primitives (string/number/boolean). For complex inputs,
	// use inline GraphQL mutations.
	const args = ['api', 'graphql', '-f', `query=${query}`];
	if (variables && typeof variables === 'object') {
		for (const [key, value] of Object.entries(variables)) {
			const t = typeof value;
			if (value == null || (t !== 'string' && t !== 'number' && t !== 'boolean')) {
				throw new Error(`graphql(): unsupported variable type for ${key} (expected primitive)`);
			}
			args.push('-F', `${key}=${value}`);
		}
	}
	const out = execFileSync('gh', args, { encoding: 'utf8' });
	return JSON.parse(out);
}

const ownerTypeCache = {};

function getOwnerType(login) {
	if (!login) return null;
	if (ownerTypeCache[login]) return ownerTypeCache[login];
	try {
		// REST is the simplest way to distinguish User vs Organization without GraphQL errors.
		const data = ghApi([`users/${login}`]);
		const t = data && data.type ? String(data.type) : null;
		ownerTypeCache[login] = t;
		return t;
	} catch (e) {
		return null;
	}
}

function getViewerLogin() {
	try {
		const res = execFileSync('gh', ['api', 'graphql', '-f', 'query={ viewer { login } }'], { encoding: 'utf8' });
		const data = JSON.parse(res);
		return data && data.data && data.data.viewer && data.data.viewer.login ? data.data.viewer.login : null;
	} catch (e) {
		return null;
	}
}

function resolveProjectNodeIdFromViewer(number) {
	const q = `query($number:Int!){ viewer{ projectV2(number:$number){ id } } }`;
	const res = execFileSync('gh', ['api', 'graphql', '-f', `query=${q}`, '-F', `number=${number}`], { encoding: 'utf8' });
	const data = JSON.parse(res);
	return data.data.viewer.projectV2.id;
}

function resolveProjectNodeIdForUser(login, number) {
	const q = `query($login:String!,$number:Int!){ user(login:$login){ projectV2(number:$number){ id } } }`;
	const res = execFileSync('gh', ['api', 'graphql', '-f', `query=${q}`, '-F', `login=${login}`, '-F', `number=${number}`], { encoding: 'utf8' });
	const data = JSON.parse(res);
	return data.data.user.projectV2.id;
}

function resolveProjectNodeIdForOrg(login, number) {
	const q = `query($login:String!,$number:Int!){ organization(login:$login){ projectV2(number:$number){ id } } }`;
	const res = execFileSync('gh', ['api', 'graphql', '-f', `query=${q}`, '-F', `login=${login}`, '-F', `number=${number}`], { encoding: 'utf8' });
	const data = JSON.parse(res);
	return data.data.organization.projectV2.id;
}

function parseProjectMirrorPath(pathStr) {
	// Formats supported:
	//  - user/<login>/projects/<number>
	//  - org/<login>/projects/<number>
	//  - viewer/projects/<number>
	if (!pathStr || typeof pathStr !== 'string') return null;
	const parts = pathStr.split('/').map(s => s.trim()).filter(Boolean);
	if (parts.length === 3 && parts[0] === 'viewer' && parts[1] === 'projects') {
		return { scope: 'viewer', number: parseInt(parts[2], 10) };
	}
	if (parts.length === 4 && (parts[0] === 'user' || parts[0] === 'org') && parts[2] === 'projects') {
		return { scope: parts[0], login: parts[1], number: parseInt(parts[3], 10) };
	}
	return null;
}

function findProjectItemIdForIssue(projectNodeId, issueNodeId) {
	if (!projectNodeId || !issueNodeId) return null;
	try {
		// Initial page
		const q0 = `query($projectId:ID!){ node(id:$projectId){ __typename ... on ProjectV2{ items(first:100){ nodes{ id content{ __typename ... on Issue{ id } ... on PullRequest{ id } } } pageInfo{ hasNextPage endCursor } } } } }`;
		let res = graphql(q0, { projectId: projectNodeId });
		let nodes = res && res.data && res.data.node && res.data.node.items && res.data.node.items.nodes ? res.data.node.items.nodes : [];
		for (const n of nodes) {
			if (n && n.content && n.content.id === issueNodeId) return n.id;
		}
		let pageInfo = res && res.data && res.data.node && res.data.node.items && res.data.node.items.pageInfo ? res.data.node.items.pageInfo : null;
		while (pageInfo && pageInfo.hasNextPage) {
			const qn = `query($projectId:ID!,$after:String){ node(id:$projectId){ __typename ... on ProjectV2{ items(first:100, after:$after){ nodes{ id content{ __typename ... on Issue{ id } ... on PullRequest{ id } } } pageInfo{ hasNextPage endCursor } } } } }`;
			res = graphql(qn, { projectId: projectNodeId, after: pageInfo.endCursor });
			nodes = res && res.data && res.data.node && res.data.node.items && res.data.node.items.nodes ? res.data.node.items.nodes : [];
			for (const n of nodes) {
				if (n && n.content && n.content.id === issueNodeId) return n.id;
			}
			pageInfo = res && res.data && res.data.node && res.data.node.items && res.data.node.items.pageInfo ? res.data.node.items.pageInfo : null;
		}
		return null;
	} catch (e) {
		console.warn('findProjectItemIdForIssue failed:', e.message);
		return null;
	}
}

function ensureProjectItem(projectNodeId, issueNodeId) {
	if (!projectNodeId || typeof projectNodeId !== 'string' || !projectNodeId.startsWith('PVT_')) {
		console.error('Invalid projectNodeId for addProjectV2ItemById:', projectNodeId);
		return null;
	}
	if (!issueNodeId || typeof issueNodeId !== 'string' || !issueNodeId.startsWith('I_')) {
		console.error('Invalid issueNodeId for addProjectV2ItemById:', issueNodeId);
		return null;
	}
	try {
		const inline = `mutation{ addProjectV2ItemById(input:{projectId:\"${projectNodeId}\",contentId:\"${issueNodeId}\"}){ item{ id } } }`;
		const out = execFileSync('gh', ['api', 'graphql', '-f', `query=${inline}`], { encoding: 'utf8' });
		const data = JSON.parse(out);
		if (data && data.data && data.data.addProjectV2ItemById && data.data.addProjectV2ItemById.item) {
			return data.data.addProjectV2ItemById.item.id;
		}
		// If the item already exists in the project, GitHub may return errors instead of data.
		// In that case, resolve the existing item id via a lookup so field updates can still apply.
		const errText = JSON.stringify(data);
		if (errText.toLowerCase().includes('already') || errText.toLowerCase().includes('exists')) {
			const existing = findProjectItemIdForIssue(projectNodeId, issueNodeId);
			if (existing) return existing;
		}
		console.error('addProjectV2ItemById: unexpected response', errText);
		return null;
	} catch (e) {
		const msg = String((e && e.message) || '');
		// Common case: the issue is already in the project. Treat as success by resolving item id.
		if (msg.toLowerCase().includes('already') || msg.toLowerCase().includes('exists')) {
			const existing = findProjectItemIdForIssue(projectNodeId, issueNodeId);
			if (existing) return existing;
		}
		console.error('addProjectV2ItemById failed:', msg);
		// Best-effort fallback: try to resolve item id even on other errors.
		try {
			const existing = findProjectItemIdForIssue(projectNodeId, issueNodeId);
			if (existing) return existing;
		} catch (_) {}
		return null;
	}
}

function escapeGraphQLString(value) {
	return String(value)
		.replace(/\\/g, '\\\\')
		.replace(/"/g, '\\"')
		.replace(/\r/g, '\\r')
		.replace(/\n/g, '\\n');
}

function formatProjectFieldValueInput(valueObj) {
	if (!valueObj || typeof valueObj !== 'object') return null;
	if (Object.prototype.hasOwnProperty.call(valueObj, 'number')) {
		return `{number:${valueObj.number}}`;
	}
	if (Object.prototype.hasOwnProperty.call(valueObj, 'date')) {
		return `{date:"${escapeGraphQLString(valueObj.date)}"}`;
	}
	if (Object.prototype.hasOwnProperty.call(valueObj, 'text')) {
		return `{text:"${escapeGraphQLString(valueObj.text)}"}`;
	}
	if (Object.prototype.hasOwnProperty.call(valueObj, 'singleSelectOptionId')) {
		return `{singleSelectOptionId:"${escapeGraphQLString(valueObj.singleSelectOptionId)}"}`;
	}
	if (Object.prototype.hasOwnProperty.call(valueObj, 'iterationId')) {
		return `{iterationId:"${escapeGraphQLString(valueObj.iterationId)}"}`;
	}
	return null;
}

function updateProjectEstimate(projectNodeId, itemId, fieldId, hours) {
	if (!projectNodeId || typeof projectNodeId !== 'string' || !projectNodeId.startsWith('PVT_')) {
		console.error('Invalid projectNodeId for updateProjectEstimate:', projectNodeId);
		return false;
	}
	if (!itemId || typeof itemId !== 'string') {
		console.error('Invalid itemId for updateProjectEstimate:', itemId);
		return false;
	}
	// The GraphQL API expects a global node ID for fieldId (not a numeric UI id).
	if (fieldId && /^[0-9]+$/.test(String(fieldId))) {
		console.error('estimateFieldId appears numeric. ProjectV2 GraphQL requires a global node id for fieldId. Skipping estimate update. Provided fieldId:', fieldId);
		return false;
	}
	try {
		const inline = `mutation{ updateProjectV2ItemFieldValue(input:{projectId:\"${projectNodeId}\",itemId:\"${itemId}\",fieldId:\"${fieldId}\",value:{number:${hours}}}){ projectV2Item{ id } } }`;
		const out = execFileSync('gh', ['api', 'graphql', '-f', `query=${inline}`], { encoding: 'utf8' });
		const data = JSON.parse(out);
		if (data && data.data && data.data.updateProjectV2ItemFieldValue) return true;
		console.error('updateProjectEstimate: unexpected response', JSON.stringify(data));
		return false;
	} catch (e) {
		console.error('updateProjectEstimate failed:', e.message);
		return false;
	}
}

function findSingleSelectOptionId(fieldNodeId, optionName) {
	if (!fieldNodeId || typeof fieldNodeId !== 'string') return null;
	try {
		// NOTE: ProjectV2 single select options are returned as a plain list (not a connection).
		const q = `query($id:ID!){ node(id:$id){ __typename ... on ProjectV2SingleSelectField{ options{ id name } } } }`;
		const res = graphql(q, { id: fieldNodeId });
		const options = res && res.data && res.data.node && Array.isArray(res.data.node.options) ? res.data.node.options : [];
		for (const n of options) {
			if (String(n.name || '').toLowerCase() === String(optionName || '').toLowerCase()) return n.id;
		}
		return null;
	} catch (e) {
		console.error('findSingleSelectOptionId failed for', fieldNodeId, e.message);
		return null;
	}
}

function updateProjectField(projectNodeId, itemId, fieldId, valueObj) {
	if (!fieldId) return false;
	if (/^[0-9]+$/.test(String(fieldId))) {
		console.warn('Project field id appears numeric. GraphQL requires global node id. Skipping field update for', fieldId);
		return false;
	}
	const valueInput = formatProjectFieldValueInput(valueObj);
	if (!valueInput) {
		console.warn('Unsupported ProjectV2 field value shape. Skipping field update for', fieldId);
		return false;
	}
	try {
		const inline = `mutation{ updateProjectV2ItemFieldValue(input:{projectId:\"${projectNodeId}\",itemId:\"${itemId}\",fieldId:\"${fieldId}\",value:${valueInput}}){ projectV2Item{ id } } }`;
		const out = execFileSync('gh', ['api', 'graphql', '-f', `query=${inline}`], { encoding: 'utf8' });
		const data = JSON.parse(out);
		if (data && data.data && data.data.updateProjectV2ItemFieldValue) return true;
		console.error('updateProjectField: unexpected response', JSON.stringify(data));
		return false;
	} catch (e) {
		console.error('updateProjectField failed:', e.message);
		return false;
	}
}

// Cache for project fields
const projectFieldsCache = {};

function loadProjectFields(projectNodeId) {
	if (projectFieldsCache[projectNodeId]) return projectFieldsCache[projectNodeId];
	try {
		const q = `query($id:ID!){ node(id:$id){ __typename ... on ProjectV2{ fields(first:100){ nodes{ ... on ProjectV2Field { id databaseId name dataType } ... on ProjectV2IterationField { id databaseId name dataType } ... on ProjectV2SingleSelectField { id databaseId name dataType } __typename } } } } }`;
		const res = graphql(q, { id: projectNodeId });
		const nodes = res && res.data && res.data.node && res.data.node.fields && res.data.node.fields.nodes ? res.data.node.fields.nodes : [];
		projectFieldsCache[projectNodeId] = nodes;
		return nodes;
	} catch (e) {
		console.error('loadProjectFields failed for', projectNodeId, e.message);
		projectFieldsCache[projectNodeId] = [];
		return [];
	}
}

function loadProjectFieldsForOrg(ownerLogin, projectNumber) {
	try {
		const q = `query($owner:String!,$number:Int!){ organization(login:$owner){ projectV2(number:$number){ fields(first:100){ nodes{ ... on ProjectV2Field { id name dataType } ... on ProjectV2IterationField { id name dataType } ... on ProjectV2SingleSelectField { id name dataType } __typename } } } } }`;
		const res = graphql(q, { owner: ownerLogin, number: projectNumber });
		const nodes = res && res.data && res.data.organization && res.data.organization.projectV2 && res.data.organization.projectV2.fields && res.data.organization.projectV2.fields.nodes ? res.data.organization.projectV2.fields.nodes : [];
		return nodes;
	} catch (e) {
		console.error('loadProjectFieldsForOrg failed for', ownerLogin, projectNumber, e.message);
		return [];
	}
}

function loadProjectFieldsForUser(ownerLogin, projectNumber) {
	try {
		const q = `query($login:String!,$number:Int!){ user(login:$login){ projectV2(number:$number){ fields(first:100){ nodes{ ... on ProjectV2Field { id name dataType } ... on ProjectV2IterationField { id name dataType } ... on ProjectV2SingleSelectField { id name dataType } __typename } } } } }`;
		const res = graphql(q, { login: ownerLogin, number: projectNumber });
		const nodes = res && res.data && res.data.user && res.data.user.projectV2 && res.data.user.projectV2.fields && res.data.user.projectV2.fields.nodes ? res.data.user.projectV2.fields.nodes : [];
		return nodes;
	} catch (e) {
		console.error('loadProjectFieldsForUser failed for', ownerLogin, projectNumber, e.message);
		return [];
	}
}

function loadProjectFieldsForOwner(ownerLogin, projectNumber) {
	const t = getOwnerType(ownerLogin);
	if (t === 'Organization') return loadProjectFieldsForOrg(ownerLogin, projectNumber);
	if (t === 'User') return loadProjectFieldsForUser(ownerLogin, projectNumber);
	// Unknown type: try user first (common), then org.
	const u = loadProjectFieldsForUser(ownerLogin, projectNumber);
	if (u && u.length) return u;
	return loadProjectFieldsForOrg(ownerLogin, projectNumber);
}

function resolveProjectFieldNodeIdByProject(ownerLogin, projectNumber, candidate) {
	if (!ownerLogin || !projectNumber || !candidate) return null;
	const fields = loadProjectFieldsForOwner(ownerLogin, projectNumber);
	if (/^[0-9]+$/.test(String(candidate))) {
		const num = parseInt(candidate, 10);
		for (const f of fields) {
			if (f.databaseId == num || String(f.databaseId) === String(num)) return f.id;
		}
	}
	const cname = String(candidate).toLowerCase();
	for (const f of fields) {
		if ((f.name || '').toLowerCase().includes(cname)) return f.id;
	}
	return null;
}

function canResolveByNodeId(projectNodeId) {
	return !!(projectNodeId && typeof projectNodeId === 'string' && projectNodeId.startsWith('PVT_'));
}

function resolveProjectFieldNodeId(projectNodeId, candidate) {
	if (!projectNodeId || !candidate) return null;
	// if candidate already looks like a global id, return it
	if (String(candidate).startsWith('PFV_') || String(candidate).startsWith('PVT_') || String(candidate).startsWith('PVF_') || String(candidate).startsWith('PVT')) return candidate;
	const fields = loadProjectFields(projectNodeId);
	// numeric databaseId
	if (/^[0-9]+$/.test(String(candidate))) {
		const num = parseInt(candidate, 10);
		for (const f of fields) {
			if (f.databaseId == num) return f.id;
		}
	}
	// match by name (case-insensitive contains)
	const cname = String(candidate).toLowerCase();
	for (const f of fields) {
		if ((f.name || '').toLowerCase().includes(cname)) return f.id;
	}
	return null;
}

async function main() {
	const args = process.argv.slice(2);
	const dryRun = args.includes('--dry-run') || args.includes('--dryrun');
	const updateOnly = args.includes('--update-only'); // NEW: Skip creation, only update existing
	const force = args.includes('--force');
	const configIndex = args.indexOf('--config');
	const inputIndex = args.indexOf('--input');
	
	let inputPath;
	let outputPath;
	let mirrorProjectPath = null; // e.g., 'user/mzfshark/projects/15'
	let mirrorEstimateFieldId = null;
	
	// Support both --config (new per-repo format) and --input (old format)
	if (configIndex >= 0 && args[configIndex + 1]) {
		// Load config to get input/output paths
		const configPath = args[configIndex + 1];
		if (!fs.existsSync(configPath)) { // nosemgrep
			console.error('Config file not found:', configPath);
			process.exit(2);
		}
		const cfg = readJson(configPath);
		const resolveBaseDirFromConfig = (cfgFilePath) => {
			try {
				const absCfg = path.isAbsolute(cfgFilePath) ? cfgFilePath : path.resolve(process.cwd(), cfgFilePath);
				return path.resolve(path.dirname(absCfg), '..', '..');
			} catch (_) {
				return process.cwd();
			}
		};
		const outBaseDir = resolveBaseDirFromConfig(configPath);
		const repoFull = cfg.repo || (cfg.owner && cfg.repoName ? `${cfg.owner}/${cfg.repoName}` : '');
		const ownerName = cfg.owner || (repoFull && repoFull.includes('/') ? repoFull.split('/')[0] : 'mzfshark');
		const repoName = repoFull && repoFull.includes('/') ? repoFull.split('/')[1] : (cfg.repoName || 'repo');
		const repoTmpDir = path.resolve(outBaseDir, 'tmp', `${ownerName}-${repoName}`);
		inputPath = cfg.outputs?.engineInputPath || path.join(repoTmpDir, 'engine-input.json');
		outputPath = cfg.outputs?.engineOutputPath || path.join(repoTmpDir, 'engine-output.json');
		// Load optional preflight snapshot for stableId resolution + conflict detection.
		try {
			const repoFromCfg = cfg.repo || null;
			const githubStatePath = resolveGithubStatePathFromConfig(configPath, cfg, repoFromCfg, outBaseDir);
			if (repoFromCfg && githubStatePath) {
				loadGithubStateIndex(repoFromCfg, githubStatePath);
			}
		} catch (_) {
			// best-effort
		}
		// Optional mirror project configuration in config file
		if (cfg.projectMirror && cfg.projectMirror.path) {
			mirrorProjectPath = cfg.projectMirror.path;
		}
		if (cfg.projectMirror && cfg.projectMirror.estimateFieldId) {
		mirrorEstimateFieldId = cfg.projectMirror.estimateFieldId;
		}
	}

	// Load engine input JSON (support --input flag)
	if (inputIndex >= 0 && args[inputIndex + 1]) {
		inputPath = args[inputIndex + 1];
	}
	if (!inputPath) inputPath = './tmp/engine-input.json';
	if (!fs.existsSync(inputPath)) { // nosemgrep
		console.error('Engine input file not found:', inputPath);
		process.exit(2);
	}
	let engine;
	try {
		engine = readJson(inputPath);
	} catch (e) {
		console.error('Failed to read engine input:', e.message);
		process.exit(2);
	}

	// Derived runtime variables
	const owner = engine.owner || engine.org || getViewerLogin() || 'mzfshark';
	const defaultAssignee = engine.defaults && engine.defaults.assignee ? engine.defaults.assignee : null;
	if (!outputPath) outputPath = './tmp/engine-output.json';
	const output = { generatedAt: new Date().toISOString(), results: [] };
	// Resolve main project node id when possible.
	// Prefer a pre-resolved node id from engine-input.json to avoid extra API calls and failures.
	let viewerProjectNodeId = null;
	const projectCfg = engine.project || {};
	if (projectCfg && (projectCfg.projectNodeId || projectCfg.nodeId)) {
		viewerProjectNodeId = projectCfg.projectNodeId || projectCfg.nodeId;
	} else if (projectCfg && projectCfg.number) {
		try {
			viewerProjectNodeId = resolveProjectNodeIdFromViewer(projectCfg.number);
		} catch (e) {
			// If it's an org project, the viewer lookup fails; try organization(login) next.
			try {
				viewerProjectNodeId = resolveProjectNodeIdForOrg(owner, projectCfg.number);
			} catch (e2) {
				console.warn('Could not resolve viewer project node id:', e.message.split('\n')[0]);
			}
		}
	}

	// Resolve mirror project node id if provided via engine or config
	let mirrorProjectNodeId = null;
	// Prefer explicit engine.project.mirrorPath if present
	if (engine.project && engine.project.mirrorPath && !mirrorProjectPath) {
		mirrorProjectPath = engine.project.mirrorPath;
	}
	if (mirrorProjectPath) {
		try {
			const parsed = parseProjectMirrorPath(mirrorProjectPath);
			if (!parsed) {
				console.warn('Mirror project path unparsable:', mirrorProjectPath);
			} else if (parsed.scope === 'viewer') {
				mirrorProjectNodeId = resolveProjectNodeIdFromViewer(parsed.number);
			} else if (parsed.scope === 'user') {
				mirrorProjectNodeId = resolveProjectNodeIdForUser(parsed.login, parsed.number);
			} else if (parsed.scope === 'org') {
				mirrorProjectNodeId = resolveProjectNodeIdForOrg(parsed.login, parsed.number);
			}
		} catch (e) {
			console.warn('Could not resolve mirror project node id:', e.message.split('\n')[0]);
		}
	}

	for (const t of engine.targets || []) {
		// Handle both formats: "repo" and "owner/repo"
		const fullRepo = t.repo.includes('/') ? t.repo : `${owner}/${t.repo}`;
		console.log('\nProcessing target:', fullRepo);
		if (!repoIsAllowed(fullRepo)) {
			console.warn('Skipping target (repo not allowed):', fullRepo);
			output.results.push({ repo: fullRepo, skipped: true, reason: 'repo not allowed' });
			continue;
		}

		const repoResult = { repo: fullRepo, tasks: [] };
		const projectCfg = engine.project || {};
		// Prefer pre-resolved viewerProjectNodeId. Accept multiple possible keys for a pre-populated node id
		// (some configs use `projectNodeId` while others use `nodeId`).
		let projectNodeId = viewerProjectNodeId || (engine.project && (engine.project.nodeId || engine.project.projectNodeId || engine.project.project_node_id || engine.project.project_id));
		if (!projectNodeId && engine.project && engine.project.projectNodeId) {
			console.warn('Using legacy engine.project.projectNodeId key for project node id');
			projectNodeId = engine.project.projectNodeId;
		}

		// If preflight snapshot exists for this repo, load it so stableId resolution and conflict
		// detection are consistent and avoid extra GitHub API calls.
		try {
			if (configIndex >= 0 && args[configIndex + 1]) {
				const configPath = args[configIndex + 1];
				const cfg = readJson(configPath);
				const githubStatePath = resolveGithubStatePathFromConfig(configPath, cfg, fullRepo);
				loadGithubStateIndex(fullRepo, githubStatePath);
			}
		} catch (_) {
			// best-effort
		}

		// Build a stableId index once per repo to avoid Search API rate limits.
		loadStableIdIndex(fullRepo);

		// Build a local parent map (tasks + subtasks) for breadcrumb titles.
		const byStableId = {};
		for (const x of (t.tasks || [])) { if (x && x.stableId) byStableId[x.stableId] = x; }
		for (const x of (t.subtasks || [])) { if (x && x.stableId) byStableId[x.stableId] = x; }

		// Preflight guard: block if a remote issue was updated after our last sync.
		// Bypass with --force.
		try {
			// Resolve repo root for registry lookup.
			let repoRootAbs = null;
			const localPath = t.localPath || (configIndex >= 0 && args[configIndex + 1] ? (readJson(args[configIndex + 1]).localPath || '.') : '.');
			if (localPath) {
				repoRootAbs = path.isAbsolute(localPath) ? localPath : path.resolve(path.dirname(process.cwd()), localPath);
				// If localPath is relative and points inside the manager repo, prefer cwd.
				if (!path.isAbsolute(localPath)) {
					repoRootAbs = path.resolve(process.cwd(), localPath);
				}
			}
			if (!repoRootAbs) repoRootAbs = process.cwd();

			const lastSyncedAtByStableId = loadRegistryLastSyncedAt(repoRootAbs);
			if (!lastSyncedAtByStableId) {
				console.warn('WARN: Preflight guard skipped (no registry found).');
			} else {
				const conflicts = [];
				const candidates = ([]).concat(t.tasks || [], t.subtasks || []);
				for (const item of candidates) {
					if (!item || !item.stableId) continue;
					const stableId = String(item.stableId);
					const lastSyncedAt = lastSyncedAtByStableId.get(stableId) || null;
					if (!lastSyncedAt) continue;
					let issue = item.canonicalKey ? findIssueByCanonicalKey(fullRepo, item.canonicalKey, updateOnly) : null;
					if (!issue) issue = findIssueByStableId(fullRepo, stableId, updateOnly);
					if (!issue && item.file) {
						const title = buildBreadcrumbTitle(item, byStableId);
						issue = findIssueBySourceTitle(fullRepo, item.file, title, updateOnly);
					}
					if (!issue) continue;
					const remoteUpdatedAt = issue.updated_at || issue.updatedAt || null;
					if (!remoteUpdatedAt) continue;
					const remoteMs = Date.parse(String(remoteUpdatedAt));
					const localMs = Date.parse(String(lastSyncedAt));
					if (!Number.isFinite(remoteMs) || !Number.isFinite(localMs)) continue;
					// 5s slack for clock skew and registry write time.
					if (remoteMs > (localMs + 5000)) {
						conflicts.push({ stableId, issueNumber: issue.number, remoteUpdatedAt: String(remoteUpdatedAt), lastSyncedAt: String(lastSyncedAt) });
					}
				}

				if (conflicts.length > 0 && !force) {
					console.error('\nERROR: Preflight guard blocked sync due to remote updates after last sync.');
					for (const c of conflicts.slice(0, 25)) {
						console.error(` - #${c.issueNumber} ${c.stableId.substring(0, 10)} remoteUpdatedAt=${c.remoteUpdatedAt} lastSyncedAt=${c.lastSyncedAt}`);
					}
					if (conflicts.length > 25) {
						console.error(` ... and ${conflicts.length - 25} more`);
					}
					console.error('HINT: Reconcile remote changes, then re-run; or bypass with --force (will overwrite issue title/body/labels).');
					process.exit(4);
				} else if (conflicts.length > 0 && force) {
					console.warn(`WARN: --force enabled; proceeding despite ${conflicts.length} preflight conflict(s).`);
				}
			}
		} catch (e) {
			console.warn('WARN: Preflight guard failed; continuing. Reason:', (e && e.message) ? e.message.split('\n')[0] : String(e));
		}

		for (const task of t.tasks || []) {
			try {
				let rawTitle = buildBreadcrumbTitle(task, byStableId);
				const title = rawTitle.length > 120 ? rawTitle.slice(0, 117) + '...' : rawTitle;
				const body = buildIssueBody(task);
								// Normalize labels and include priority
								const labels = normalizeLabels(task.labels, ['sync-md']);
								if (task.priority) labels.push(task.priority);

								// Normalize labels: ensure a `type:` label exists
				if (!labels.some(l => /^type:/i.test(l))) {
					const text = (task.text || '').toLowerCase();
					if (text.includes('bug') || text.includes('error')) labels.push('type:bug');
					else if (text.includes('feature')) labels.push('type:feature');
					else labels.push('type:task');
				}

				let issue = task.canonicalKey ? findIssueByCanonicalKey(fullRepo, task.canonicalKey, updateOnly) : null;
				if (!issue) issue = findIssueByStableId(fullRepo, task.stableId, updateOnly);
				if (!issue && task.file && !task.canonicalKey) {
					issue = findIssueBySourceTitle(fullRepo, task.file, title, updateOnly);
				}
				let created = false;
				let wouldCreate = false;
				let wouldUpdate = false;
				if (issue) {
					if (dryRun) {
						console.log('[DRY-RUN] Would update issue', issue.number, 'for', task.stableId.substring(0, 10));
						wouldUpdate = true;
					} else {
						console.log('Updating issue', issue.number, 'for', task.stableId.substring(0, 10));
						const upd = updateIssue(fullRepo, issue.number, title, body, labels.concat([]));
						issue = upd;
					}
				} else {
					// NEW: Skip creation if --update-only flag is set
					if (updateOnly) {
						console.log('[SKIP] No existing issue for', task.stableId.substring(0, 10), '(update-only mode)');
						const taskResult = { stableId: task.stableId, issueNumber: null, issueNodeId: null, created: false, skipped: true, reason: 'update-only' };
						repoResult.tasks.push(taskResult);
						continue;
					}
					if (dryRun) {
						console.log('[DRY-RUN] Would create issue for', task.stableId.substring(0, 10));
						wouldCreate = true;
						const taskResult = { stableId: task.stableId, issueNumber: null, issueNodeId: null, created: false, wouldCreate: true };
						repoResult.tasks.push(taskResult);
						continue;
					}
					console.log('Creating issue for', task.stableId.substring(0, 10));
					// NEW: Use task.assignee for parent plans, fallback to defaultAssignee
					const effectiveAssignee = task.isParentPlan && task.assignee 
						? task.assignee 
						: defaultAssignee;
					const assignees = effectiveAssignee ? [effectiveAssignee] : [];
					const createdIssue = (function(){
						try {
							const args = [`repos/${fullRepo}/issues`, '-f', `title=${title}`, '-f', `body=${body}`];
							for (const l of labels || []) args.push('-f', `labels[]=${l}`);
							for (const a of assignees) args.push('-f', `assignees[]=${a}`);
							return ghApi(args);
						} catch (e) { throw e; }
					})();
					if (!createdIssue || !createdIssue.number) {
						throw new Error('Failed to create issue: no issue number returned');
					}
					issue = createdIssue;
					created = true;
				}

				// Sync open/closed based on status/checkbox state.
				if (!dryRun && issue && issue.number) {
					try {
						const desired = desiredIssueStateFromItem(task);
						const current = String(issue.state || '').toLowerCase();
						if ((desired === 'closed' || desired === 'open') && current && desired !== current) {
							setIssueState(fullRepo, issue.number, desired);
						}
					} catch (e) {
						console.warn('WARN: Could not sync issue state for', task.stableId.substring(0, 10), '-', (e && e.message) ? e.message.split('\n')[0] : String(e));
					}
				}

				const issueNumber = issue.number;
				const issueNodeId = issue.node_id || issue.nodeId || null;

				const taskResult = { stableId: task.stableId, issueNumber, issueNodeId, created, wouldCreate, wouldUpdate };

				if (!dryRun && t.enableProjectSync && projectNodeId && issueNodeId) {
					try {
						const projectItemId = ensureProjectItem(projectNodeId, issueNodeId);
						taskResult.projectItemId = projectItemId;
						// Resolve configured fields (accept numeric ids or names) and set defaults
						const cfgFields = (engine.project && engine.project.fieldIds) || {};
						const estimateFieldCandidate = cfgFields.estimateHoursFieldId || cfgFields.estimateFieldId || null;
						const startFieldCandidate = cfgFields.startDateFieldId || cfgFields.startFieldId || null;
						const endFieldCandidate = cfgFields.endDateFieldId || cfgFields.endFieldId || null;
						const statusFieldCandidate = cfgFields.statusFieldId || null;
						const priorityFieldCandidate = cfgFields.priorityFieldId || null;

						// Prefer resolving via projectNodeId (node query). Fallback to owner/projectNumber only when node id is missing.
						const projectNumber = (engine.project && engine.project.number) || null;
						let estimateFieldNodeId = canResolveByNodeId(projectNodeId)
							? resolveProjectFieldNodeId(projectNodeId, estimateFieldCandidate)
							: (projectNumber ? resolveProjectFieldNodeIdByProject(owner, projectNumber, estimateFieldCandidate) : null);
						if (!estimateFieldNodeId) {
							estimateFieldNodeId = canResolveByNodeId(projectNodeId)
								? resolveProjectFieldNodeId(projectNodeId, 'estimate')
								: (projectNumber ? resolveProjectFieldNodeIdByProject(owner, projectNumber, 'estimate') : null);
						}
						if (estimateFieldNodeId && task.estimateHours != null) {
							updateProjectField(projectNodeId, projectItemId, estimateFieldNodeId, { number: task.estimateHours });
						}

						// Dates: default start=today, end=+7 days when not provided
						const today = new Date();
						const yyyy = today.getUTCFullYear();
						const mm = String(today.getUTCMonth()+1).padStart(2,'0');
						const dd = String(today.getUTCDate()).padStart(2,'0');
						const startDateStr = (task.startDate && task.startDate !== 'TBD') ? task.startDate : `${yyyy}-${mm}-${dd}`;
						const end = new Date(today.getTime()); end.setUTCDate(end.getUTCDate()+7);
						const eyyyy = end.getUTCFullYear(); const emm = String(end.getUTCMonth()+1).padStart(2,'0'); const edd = String(end.getUTCDate()).padStart(2,'0');
						const endDateStr = (task.endDate && task.endDate !== 'TBD') ? task.endDate : `${eyyyy}-${emm}-${edd}`;
												let startFieldNodeId = canResolveByNodeId(projectNodeId)
													? resolveProjectFieldNodeId(projectNodeId, startFieldCandidate)
													: (projectNumber ? resolveProjectFieldNodeIdByProject(owner, projectNumber, startFieldCandidate) : null);
												if (!startFieldNodeId) {
													startFieldNodeId = canResolveByNodeId(projectNodeId)
														? resolveProjectFieldNodeId(projectNodeId, 'start')
														: (projectNumber ? resolveProjectFieldNodeIdByProject(owner, projectNumber, 'start') : null);
												}
												if (startFieldNodeId) updateProjectField(projectNodeId, projectItemId, startFieldNodeId, { date: startDateStr });
												let endFieldNodeId = canResolveByNodeId(projectNodeId)
													? resolveProjectFieldNodeId(projectNodeId, endFieldCandidate)
													: (projectNumber ? resolveProjectFieldNodeIdByProject(owner, projectNumber, endFieldCandidate) : null);
												if (!endFieldNodeId) {
													endFieldNodeId = canResolveByNodeId(projectNodeId)
														? resolveProjectFieldNodeId(projectNodeId, 'end')
														: (projectNumber ? resolveProjectFieldNodeIdByProject(owner, projectNumber, 'end') : null);
												}
												if (endFieldNodeId) updateProjectField(projectNodeId, projectItemId, endFieldNodeId, { date: endDateStr });

										// Status / Priority: single-select fields â€” map by option name
												const statusFieldNodeId = canResolveByNodeId(projectNodeId)
													? resolveProjectFieldNodeId(projectNodeId, statusFieldCandidate || 'Status')
													: (projectNumber ? resolveProjectFieldNodeIdByProject(owner, projectNumber, statusFieldCandidate || 'Status') : null);
												const priorityFieldNodeId = canResolveByNodeId(projectNodeId)
													? resolveProjectFieldNodeId(projectNodeId, priorityFieldCandidate || 'Priority')
													: (projectNumber ? resolveProjectFieldNodeIdByProject(owner, projectNumber, priorityFieldCandidate || 'Priority') : null);
						if (statusFieldNodeId) {
							const desired = (task.status || engine.defaults && engine.defaults.defaultStatus || 'Backlog');
							const optId = findSingleSelectOptionId(statusFieldNodeId, desired);
							if (optId) updateProjectField(projectNodeId, projectItemId, statusFieldNodeId, { singleSelectOptionId: optId });
						}
						if (priorityFieldNodeId) {
							const desiredPr = (task.priority || engine.defaults && engine.defaults.defaultPriority || 'low');
							const optId = findSingleSelectOptionId(priorityFieldNodeId, desiredPr);
							if (optId) updateProjectField(projectNodeId, projectItemId, priorityFieldNodeId, { singleSelectOptionId: optId });
						}
					} catch (e) {
						console.error('Project attach/update failed for', task.stableId, e.message);
					}
				}

				// Mirror into secondary project if configured
				if (!dryRun && issueNodeId && mirrorProjectNodeId) {
					try {
						const mirrorItemId = ensureProjectItem(mirrorProjectNodeId, issueNodeId);
						taskResult.mirrorProjectItemId = mirrorItemId;
						if (mirrorEstimateFieldId && task.estimateHours != null) {
							updateProjectEstimate(mirrorProjectNodeId, mirrorItemId, mirrorEstimateFieldId, task.estimateHours);
						}
					} catch (e) {
						console.error('Mirror project attach/update failed for', task.stableId, e.message);
					}
				}

				repoResult.tasks.push(taskResult);
			} catch (e) {
				const isRateLimit = e.message && e.message.includes('RATE_LIMIT');
				console.error(isRateLimit ? '[RATE_LIMIT]' : '[ERROR]', 'Failed to process task', task.stableId.substring(0, 10), e.message.substring(0, 80));
				repoResult.tasks.push({ stableId: task.stableId, error: e.message, rateLimit: isRateLimit });
				if (isRateLimit) {
					console.warn('\nâš ï¸  Rate limit hit. Stopping execution. Remaining tasks:', (t.tasks.length + t.subtasks.length) - repoResult.tasks.length);
					break;
				}
			}
		}

		for (const s of t.subtasks || []) {
			try {
				const parentIssue = repoResult.tasks.find(x => x.stableId === s.parentStableId);
				let parentNumber = parentIssue && parentIssue.issueNumber ? parentIssue.issueNumber : null;
				let parentIssueNodeId = parentIssue && parentIssue.issueNodeId ? parentIssue.issueNodeId : null;
				// If the parent wasn't part of this run's task list (common for legacy plans), resolve it by stableId.
				if ((parentNumber == null || !parentIssueNodeId) && s.parentStableId) {
					const p = findIssueByStableId(fullRepo, String(s.parentStableId), updateOnly);
					if (p) {
						if (parentNumber == null && p.number) parentNumber = p.number;
						if (!parentIssueNodeId && (p.node_id || p.nodeId)) parentIssueNodeId = p.node_id || p.nodeId;
					}
				}
				let subRawTitle = buildBreadcrumbTitle(s, byStableId);
				const title = subRawTitle.length > 120 ? subRawTitle.slice(0, 117) + '...' : subRawTitle;
				let body = buildIssueBody(s);
				if (parentNumber) body = `Parent: #${parentNumber}\n\n` + body;
				const labels = normalizeLabels(s.labels, ['subtask', 'sync-md']);
				if (s.priority) labels.push(s.priority);
				// Ensure subtask label + default type
				const subLabels = normalizeLabels(s.labels, ['subtask', 'sync-md']);
				if (!subLabels.some(l => /^type:/i.test(l))) {
					const stxt = (s.text || '').toLowerCase();
					if (stxt.includes('bug') || stxt.includes('error')) subLabels.push('type:bug');
					else if (stxt.includes('feature')) subLabels.push('type:feature');
					else subLabels.push('type:task');
				}
				let issue = s.canonicalKey ? findIssueByCanonicalKey(fullRepo, s.canonicalKey, updateOnly) : null;
				if (!issue) issue = findIssueByStableId(fullRepo, s.stableId, updateOnly);
				if (!issue && s.file && !s.canonicalKey) {
					issue = findIssueBySourceTitle(fullRepo, s.file, title, updateOnly);
				}
				let created = false;
				let wouldCreate = false;
				let wouldUpdate = false;
				if (issue) {
					if (dryRun) {
						console.log('[DRY-RUN] Would update subtask', issue.number, 'for', s.stableId.substring(0, 10));
						wouldUpdate = true;
					} else {
						const upd = updateIssue(fullRepo, issue.number, title, body, subLabels.concat([]));
						issue = upd;
					}
				} else {
					// NEW: Skip creation if --update-only flag is set
					if (updateOnly) {
						console.log('[SKIP] No existing subtask for', s.stableId.substring(0, 10), '(update-only mode)');
						const subResult = { stableId: s.stableId, issueNumber: null, issueNodeId: null, created: false, skipped: true, reason: 'update-only', parentStableId: s.parentStableId };
						repoResult.tasks.push(subResult);
						continue;
					}
					if (dryRun) {
						console.log('[DRY-RUN] Would create subtask for', s.stableId.substring(0, 10));
						wouldCreate = true;
						const subResult = { stableId: s.stableId, issueNumber: null, issueNodeId: null, created: false, wouldCreate: true, parentStableId: s.parentStableId };
						repoResult.tasks.push(subResult);
						continue;
					}
					const assignees = defaultAssignee ? [defaultAssignee] : [];
					const createdIssue = (function(){
						try {
							const args = [`repos/${fullRepo}/issues`, '-f', `title=${title}`, '-f', `body=${body}`];
							for (const l of subLabels || []) args.push('-f', `labels[]=${l}`);
							for (const a of assignees) args.push('-f', `assignees[]=${a}`);
							return ghApi(args);
						} catch (e) { throw e; }
					})();
					if (!createdIssue || !createdIssue.number) {
						throw new Error('Failed to create subtask: no issue number returned');
					}
					issue = createdIssue;
					created = true;
				}

				// Sync open/closed based on status/checkbox state.
				if (!dryRun && issue && issue.number) {
					try {
						const desired = desiredIssueStateFromItem(s);
						const current = String(issue.state || '').toLowerCase();
						if ((desired === 'closed' || desired === 'open') && current && desired !== current) {
							setIssueState(fullRepo, issue.number, desired);
						}
					} catch (e) {
						console.warn('WARN: Could not sync issue state for subtask', s.stableId.substring(0, 10), '-', (e && e.message) ? e.message.split('\n')[0] : String(e));
					}
				}
				const subIssueNodeId = issue.node_id || null;

				const subResult = { stableId: s.stableId, issueNumber: issue.number, issueNodeId: subIssueNodeId, created, wouldCreate, wouldUpdate, parentStableId: s.parentStableId };

				// Attach subtasks to the main project as well (not only top-level tasks).
				if (!dryRun && t.enableProjectSync && projectNodeId && subIssueNodeId) {
					try {
						const projectItemId = ensureProjectItem(projectNodeId, subIssueNodeId);
						subResult.projectItemId = projectItemId;

						// Ensure the parent issue is also present in the project when subtasks are.
						// GitHub Projects doesn't automatically add parents when a sub-issue is added.
						if (parentIssueNodeId) {
							const parentProjectItemId = ensureProjectItem(projectNodeId, parentIssueNodeId);
							if (parentProjectItemId && parentIssue && !parentIssue.projectItemId) {
								parentIssue.projectItemId = parentProjectItemId;
							}
						}

						const cfgFields = (engine.project && engine.project.fieldIds) || {};
						const estimateFieldCandidate = cfgFields.estimateHoursFieldId || cfgFields.estimateFieldId || null;
						const startFieldCandidate = cfgFields.startDateFieldId || cfgFields.startFieldId || null;
						const endFieldCandidate = cfgFields.endDateFieldId || cfgFields.endFieldId || null;
						const statusFieldCandidate = cfgFields.statusFieldId || null;
						const priorityFieldCandidate = cfgFields.priorityFieldId || null;
						const projectNumber = (engine.project && engine.project.number) || null;

						let estimateFieldNodeId = canResolveByNodeId(projectNodeId)
							? resolveProjectFieldNodeId(projectNodeId, estimateFieldCandidate)
							: (projectNumber ? resolveProjectFieldNodeIdByProject(owner, projectNumber, estimateFieldCandidate) : null);
						if (!estimateFieldNodeId) {
							estimateFieldNodeId = canResolveByNodeId(projectNodeId)
								? resolveProjectFieldNodeId(projectNodeId, 'estimate')
								: (projectNumber ? resolveProjectFieldNodeIdByProject(owner, projectNumber, 'estimate') : null);
						}
						if (estimateFieldNodeId && s.estimateHours != null) {
							updateProjectField(projectNodeId, projectItemId, estimateFieldNodeId, { number: s.estimateHours });
						}

						const today = new Date();
						const yyyy = today.getUTCFullYear();
						const mm = String(today.getUTCMonth() + 1).padStart(2, '0');
						const dd = String(today.getUTCDate()).padStart(2, '0');
						const startDateStr = (s.startDate && s.startDate !== 'TBD') ? s.startDate : `${yyyy}-${mm}-${dd}`;
						const end = new Date(today.getTime());
						end.setUTCDate(end.getUTCDate() + 7);
						const eyyyy = end.getUTCFullYear();
						const emm = String(end.getUTCMonth() + 1).padStart(2, '0');
						const edd = String(end.getUTCDate()).padStart(2, '0');
						const endDateStr = (s.endDate && s.endDate !== 'TBD') ? s.endDate : `${eyyyy}-${emm}-${edd}`;

						let startFieldNodeId = canResolveByNodeId(projectNodeId)
							? resolveProjectFieldNodeId(projectNodeId, startFieldCandidate)
							: (projectNumber ? resolveProjectFieldNodeIdByProject(owner, projectNumber, startFieldCandidate) : null);
						if (!startFieldNodeId) {
							startFieldNodeId = canResolveByNodeId(projectNodeId)
								? resolveProjectFieldNodeId(projectNodeId, 'start')
								: (projectNumber ? resolveProjectFieldNodeIdByProject(owner, projectNumber, 'start') : null);
						}
						if (startFieldNodeId) updateProjectField(projectNodeId, projectItemId, startFieldNodeId, { date: startDateStr });
						let endFieldNodeId = canResolveByNodeId(projectNodeId)
							? resolveProjectFieldNodeId(projectNodeId, endFieldCandidate)
							: (projectNumber ? resolveProjectFieldNodeIdByProject(owner, projectNumber, endFieldCandidate) : null);
						if (!endFieldNodeId) {
							endFieldNodeId = canResolveByNodeId(projectNodeId)
								? resolveProjectFieldNodeId(projectNodeId, 'end')
								: (projectNumber ? resolveProjectFieldNodeIdByProject(owner, projectNumber, 'end') : null);
						}
						if (endFieldNodeId) updateProjectField(projectNodeId, projectItemId, endFieldNodeId, { date: endDateStr });

						const statusFieldNodeId = canResolveByNodeId(projectNodeId)
							? resolveProjectFieldNodeId(projectNodeId, statusFieldCandidate || 'Status')
							: (projectNumber ? resolveProjectFieldNodeIdByProject(owner, projectNumber, statusFieldCandidate || 'Status') : null);
						const priorityFieldNodeId = canResolveByNodeId(projectNodeId)
							? resolveProjectFieldNodeId(projectNodeId, priorityFieldCandidate || 'Priority')
							: (projectNumber ? resolveProjectFieldNodeIdByProject(owner, projectNumber, priorityFieldCandidate || 'Priority') : null);
						if (statusFieldNodeId) {
							const desired = (s.status || (engine.defaults && engine.defaults.defaultStatus) || 'Backlog');
							const optId = findSingleSelectOptionId(statusFieldNodeId, desired);
							if (optId) updateProjectField(projectNodeId, projectItemId, statusFieldNodeId, { singleSelectOptionId: optId });
						}
						if (priorityFieldNodeId) {
							const desiredPr = (s.priority || (engine.defaults && engine.defaults.defaultPriority) || 'low');
							const optId = findSingleSelectOptionId(priorityFieldNodeId, desiredPr);
							if (optId) updateProjectField(projectNodeId, projectItemId, priorityFieldNodeId, { singleSelectOptionId: optId });
						}
					} catch (e) {
						console.error('Project attach/update failed for subtask', s.stableId, e.message);
					}
				}

				// Mirror subtasks as well
				if (!dryRun && subIssueNodeId && mirrorProjectNodeId) {
					try {
						const mirrorItemId = ensureProjectItem(mirrorProjectNodeId, subIssueNodeId);
						subResult.mirrorProjectItemId = mirrorItemId;
						if (mirrorEstimateFieldId && s.estimateHours != null) {
							updateProjectEstimate(mirrorProjectNodeId, mirrorItemId, mirrorEstimateFieldId, s.estimateHours);
						}
					} catch (e) {
						console.error('Mirror project attach/update failed for subtask', s.stableId, e.message);
					}
				}

				repoResult.tasks.push(subResult);
			} catch (e) {
				const isRateLimit = e.message && e.message.includes('RATE_LIMIT');
				console.error(isRateLimit ? '[RATE_LIMIT]' : '[ERROR]', 'Failed to process subtask', s.stableId.substring(0, 10), e.message.substring(0, 80));
				repoResult.tasks.push({ stableId: s.stableId, error: e.message, parentStableId: s.parentStableId, rateLimit: isRateLimit });
				if (isRateLimit) {
					console.warn('\nâš ï¸  Rate limit hit on subtasks. Stopping.');
					break;
				}
			}
		}

		output.results.push(repoResult);
	}

	writeJson(outputPath, output);
	console.log('\nâœ“ Execution complete');
	console.log('Output written to:', outputPath);
}

main();
