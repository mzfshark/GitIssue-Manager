#!/usr/bin/env node
// Server-side executor (engine):
// - Reads engine-input.json generated by client/prepare.js
// - Creates/updates issues in mzfshark/* repos (idempotent via stableId)
// - Optionally attaches issues to ProjectV2 and updates estimate field

const fs = require('fs');
const path = require('path');
const { execFileSync } = require('child_process');

function readJson(p) { return JSON.parse(fs.readFileSync(p, 'utf8')); }
function writeJson(p, obj) { fs.mkdirSync(path.dirname(p), { recursive: true }); fs.writeFileSync(p, JSON.stringify(obj, null, 2)); }

function ghApi(args) {
	try {
		const out = execFileSync('gh', ['api', ...args], { encoding: 'utf8' });
		return JSON.parse(out);
	} catch (e) {
		if (e.stdout) {
			try { return JSON.parse(e.stdout.toString()); } catch (_) {}
		}
		throw e;
	}
}

function ghExec(args) {
	return execFileSync('gh', ['api', ...args], { encoding: 'utf8' });
}

function repoIsAllowed(repo) {
	return repo && repo.startsWith('mzfshark/');
}

function findIssueByStableId(repo, stableId) {
	const q = `repo:${repo} StableId:${stableId}`;
	try {
		const res = ghApi(['search/issues', '-f', `q=${q}`]);
		if (res && res.total_count && res.items && res.items.length) {
			console.log('[DEBUG] Found existing issue:', res.items[0].number, 'for', stableId.substring(0, 10));
			return res.items[0];
		}
		return null;
	} catch (e) {
		// 404 or search errors just mean no issue found
		if (!e.message.includes('HTTP 404')) {
			console.warn('[WARN] search issues failed:', e.message.substring(0, 80));
		}
		return null;
	}
}

function createIssue(repo, title, body, labels) {
	const args = [`repos/${repo}/issues`, '-f', `title=${title}`, '-f', `body=${body}`];
	for (const l of labels || []) args.push('-f', `labels[]=${l}`);
	try {
		const out = ghApi(args);
		return out;
	} catch (e) {
		if (e.message && e.message.includes('rate limit')) {
			throw new Error('RATE_LIMIT: ' + e.message.substring(0, 100));
		}
		throw e;
	}
}

function updateIssue(repo, number, title, body, labels) {
	const args = [`repos/${repo}/issues/${number}`, '-X', 'PATCH', '-f', `title=${title}`, '-f', `body=${body}`];
	for (const l of labels || []) args.push('-f', `labels[]=${l}`);
	const out = ghApi(args);
	return out;
}

function graphql(query, variables) {
	const out = execFileSync('gh', ['api', 'graphql', '-f', `query=${query}`, '-f', `variables=${JSON.stringify(variables)}`], { encoding: 'utf8' });
	return JSON.parse(out);
}

function ensureProjectItem(projectNodeId, issueNodeId) {
	const mutation = `mutation($input:AddProjectV2ItemByIdInput!){ addProjectV2ItemById(input:$input){ item{ id } } }`;
	const variables = { input: { projectId: projectNodeId, contentId: issueNodeId } };
	try {
		const res = graphql(mutation, variables);
		return res.data.addProjectV2ItemById.item.id;
	} catch (e) {
		console.error('addProjectV2ItemById failed:', e.message);
		return null;
	}
}

function updateProjectEstimate(projectNodeId, itemId, fieldId, hours) {
	const mutation = `mutation($input:UpdateProjectV2ItemFieldValueInput!){ updateProjectV2ItemFieldValue(input:$input){ projectV2Item{ id } } }`;
	const variables = { input: { projectId: projectNodeId, itemId, fieldId, value: { number: hours } } };
	try {
		graphql(mutation, variables);
		return true;
	} catch (e) {
		console.error('updateProjectEstimate failed:', e.message);
		return false;
	}
}

async function main() {
	const args = process.argv.slice(2);
	const configIndex = args.indexOf('--config');
	const inputIndex = args.indexOf('--input');
	
	let inputPath;
	let outputPath;
	
	// Support both --config (new per-repo format) and --input (old format)
	if (configIndex >= 0 && args[configIndex + 1]) {
		// Load config to get input/output paths
		const configPath = args[configIndex + 1];
		if (!fs.existsSync(configPath)) {
			console.error('Config file not found:', configPath);
			process.exit(2);
		}
		const cfg = readJson(configPath);
		inputPath = cfg.outputs?.engineInputPath || './tmp/engine-input.json';
		outputPath = cfg.outputs?.engineOutputPath || './tmp/engine-output.json';
	} else {
		// Old format: explicit --input or default
		inputPath = (inputIndex >= 0 && args[inputIndex + 1]) ? args[inputIndex + 1] : './tmp/engine-input.json';
		outputPath = inputPath.replace('engine-input.json', 'engine-output.json');
	}

	if (!fs.existsSync(inputPath)) {
		console.error('Engine input not found:', inputPath);
		console.error('Run: npm run prepare');
		process.exit(2);
	}

	console.log('\nReading engine input:', inputPath);
	const engine = readJson(inputPath);
	const output = { ...engine, executedAt: new Date().toISOString(), results: [] };
	const owner = engine.owner || 'mzfshark';

	for (const t of engine.targets || []) {
		// Handle both formats: "repo" and "owner/repo"
		const fullRepo = t.repo.includes('/') ? t.repo : `${owner}/${t.repo}`;
		console.log('\nProcessing target:', fullRepo);
		if (!repoIsAllowed(fullRepo)) {
			console.warn('Skipping target (repo not allowed):', fullRepo);
			output.results.push({ repo: fullRepo, skipped: true, reason: 'repo not allowed' });
			continue;
		}

		const repoResult = { repo: fullRepo, tasks: [] };
		const projectCfg = engine.project || {};
		let projectNodeId = engine.project && engine.project.nodeId;
		if (!projectNodeId && projectCfg.number) {
			try {
				const q = `query($number:Int!){ viewer{ projectV2(number:$number){ id } } }`;
				const vars = { number: projectCfg.number };
				const res = graphql(q, vars);
				projectNodeId = res.data.viewer.projectV2.id;
			} catch (e) {
				console.warn('Could not resolve project node id:', e.message);
			}
		}

		for (const task of t.tasks || []) {
			try {
				const title = task.text.length > 120 ? task.text.slice(0, 117) + '...' : task.text;
				const body = `Source: ${task.file}#L${task.line}\n\nStableId: ${task.stableId}\n\n${task.text}`;
				const labels = ['sync-md'];
				if (task.priority) labels.push(task.priority);

				let issue = findIssueByStableId(fullRepo, task.stableId);
				let created = false;
				if (issue) {
					console.log('Updating issue', issue.number, 'for', task.stableId.substring(0, 10));
					const upd = updateIssue(fullRepo, issue.number, title, body, labels);
					issue = upd;
				} else {
					console.log('Creating issue for', task.stableId.substring(0, 10));
					const createdIssue = createIssue(fullRepo, title, body, labels);
					if (!createdIssue || !createdIssue.number) {
						throw new Error('Failed to create issue: no issue number returned');
					}
					issue = createdIssue;
					created = true;
				}

				const issueNumber = issue.number;
				const issueNodeId = issue.node_id || issue.nodeId || null;

				const taskResult = { stableId: task.stableId, issueNumber, issueNodeId, created };

				if (t.enableProjectSync && projectNodeId && issueNodeId) {
					try {
						const projectItemId = ensureProjectItem(projectNodeId, issueNodeId);
						taskResult.projectItemId = projectItemId;
						const estimateFieldId = (engine.project && engine.project.fieldIds && engine.project.fieldIds.estimateHoursFieldId) || null;
						if (estimateFieldId && task.estimateHours != null) {
							updateProjectEstimate(projectNodeId, projectItemId, estimateFieldId, task.estimateHours);
						}
					} catch (e) {
						console.error('Project attach/update failed for', task.stableId, e.message);
					}
				}

				repoResult.tasks.push(taskResult);
			} catch (e) {
				const isRateLimit = e.message && e.message.includes('RATE_LIMIT');
				console.error(isRateLimit ? '[RATE_LIMIT]' : '[ERROR]', 'Failed to process task', task.stableId.substring(0, 10), e.message.substring(0, 80));
				repoResult.tasks.push({ stableId: task.stableId, error: e.message, rateLimit: isRateLimit });
				if (isRateLimit) {
					console.warn('\n⚠️  Rate limit hit. Stopping execution. Remaining tasks:', (t.tasks.length + t.subtasks.length) - repoResult.tasks.length);
					break;
				}
			}
		}

		for (const s of t.subtasks || []) {
			try {
				const parentIssue = repoResult.tasks.find(x => x.stableId === s.parentStableId);
				const parentNumber = parentIssue && parentIssue.issueNumber;
				const title = s.text.length > 120 ? s.text.slice(0, 117) + '...' : s.text;
				let body = `Source: ${s.file}#L${s.line}\n\nStableId: ${s.stableId}\n\n${s.text}`;
				if (parentNumber) body = `Parent: #${parentNumber}\n\n` + body;
				const labels = ['subtask','sync-md'];
				let issue = findIssueByStableId(fullRepo, s.stableId);
				let created = false;
				if (issue) {
					const upd = updateIssue(fullRepo, issue.number, title, body, labels);
					issue = upd;
				} else {
					const createdIssue = createIssue(fullRepo, title, body, labels);
					if (!createdIssue || !createdIssue.number) {
						throw new Error('Failed to create subtask: no issue number returned');
					}
					issue = createdIssue;
					created = true;
				}
				repoResult.tasks.push({ stableId: s.stableId, issueNumber: issue.number, issueNodeId: issue.node_id || null, created, parentStableId: s.parentStableId });
			} catch (e) {
				const isRateLimit = e.message && e.message.includes('RATE_LIMIT');
				console.error(isRateLimit ? '[RATE_LIMIT]' : '[ERROR]', 'Failed to process subtask', s.stableId.substring(0, 10), e.message.substring(0, 80));
				repoResult.tasks.push({ stableId: s.stableId, error: e.message, parentStableId: s.parentStableId, rateLimit: isRateLimit });
				if (isRateLimit) {
					console.warn('\n⚠️  Rate limit hit on subtasks. Stopping.');
					break;
				}
			}
		}

		output.results.push(repoResult);
	}

	writeJson(outputPath, output);
	console.log('\n✓ Execution complete');
	console.log('Output written to:', outputPath);
}

main();
